---
slug: "covid19deathspercapita"
title: "Deaths per capita from COVID-19 are more informative than confirmed cases"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
author: "Rory Nolan"
date: "`r lubridate::today()`"
categories: ["COVID-19"]
tags: ["COVID-19", "coronavirus"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", echo = FALSE,
                      fig.height = 5, fig.width = 10, message = FALSE)
```

The rate of testing for COVID-19 is increasing in many countries. As such, using the number of confirmed cases over time is not a reliable method for tracking the spread of the disease. Nevertheless, many articles---including [this one](https://www.ft.com/content/a26fbf7e-48f8-11ea-aeb3-955839e06441) in the _Financial Times_---still talk about the number of confirmed cases. That article also focuses on number of deaths though, which is much better and leads us to what I think should be used.


# We should be using deaths per capita

First of all, we should be using per capita statistics. For example, 100,000 cases in China vs 100,000 cases in Ireland would be very different things, because of what they imply for concentration of cases. Per capita (assuming a billion people in China and 5 million in Ireland), this would mean 1% of people in Ireland have the disease compared to 0.01% of people in China: 1 in 100 vs 1 in 10,000. Of course, just using per capita by country, you miss a lot too. A particularly high concentration of cases in Wuhan is not the same as a more even spread of cases throughout China. You can fix this by dividing by province or county (if you have that level of granularity in your data); I do this by state for the US. I'm going to use per million people instead of per capita, because it's a bit easier to think about.

Second, reported deaths from the virus are more reliable than confirmed cases. That's because the more ill you are, the more likely you are to get a test. The number of people _reported_ to have died of COVID-19 infection will be closer to the true number of people who died of COVID-19 than the number of people _reported_ to be infected will be to the true number of infected individuals.

For timelining, I'll use days since the tenth confirmed death from COVID-19 in a particular country, just like the _Financial Times_ article. 


## Deaths per capita will lag other measures

I don't mean to say that deaths per capita is the only useful thing. It actually lags other measures (in particular the number of infected individuals) by a few days because the disease does not kill quickly. In particular, if a countries rate of testing is steady or increasing but the absolute number of people testing positive per day is decreasing, that's a great sign and a sign that you'll see sooner than a drop in deaths.


# Data source, preparation and limitations

Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) has put together a great [COVID-19 data repository](https://github.com/CSSEGISandData/COVID-19). Note that I've smoothed the data to make the plots more readable. This means that only sustained changes will appear on the plots (e.g. a one-day drop in deaths will be smoothed out). This is a good thing as it prevents us from reading too much into single data. Bear in mind that different countries have different measurement methods and capabilities, so they aren't strictly comparable. However, provided that within a given country, the measurements are done in a consistent manner, one can still do reliable comparisons of the _shapes_ of the countries' curves.

```{r prep-data}
pacman::p_load(tidyverse, countrycode, wbstats, directlabels)

total_deaths_thresh <- 100

data_url <- str_c(
  "https://raw.githubusercontent.com/", 
  "RamiKrispin/coronavirus-csv/master/coronavirus_dataset.csv"
)
stopifnot(RCurl::url.exists(data_url))
raw_data <- read_csv(data_url, guess_max = 1e6)

countries_iso3c <- tibble(
  country = sort(unique(raw_data$Country.Region))
) %>% 
  filter(!str_detect(country, "(Kosovo|Cruise Ship|Diamond Princess)")) %>%  # not recognised by countrycodes package
  mutate(iso3c = countrycode(country, "country.name", "iso3c")) %>% 
  filter(!is.element(iso3c, c("VAT", "MTQ")))  # not included in world bank data

country_pops <- wb(
  country = countries_iso3c$iso3c,
  indicator = "SP.POP.TOTL", 
  startdate = 2018, enddate = 2018
) %>% 
  select(iso3c, value) %>% 
  inner_join(countries_iso3c, by = c("iso3c" = "iso3c")) %>% 
  select(country, value) %>% 
  rename(population = value)



data <- raw_data %>% 
  janitor::clean_names() %>% 
  dplyr::filter(type == "death") %>% 
  rename(country = country_region, deaths = cases) %>% 
  group_by(country, date) %>% 
  summarise_at("deaths", sum) %>% 
  ungroup() %>% 
  add_count(country, wt = deaths, name = "total_deaths") %>% 
  filter(total_deaths >= total_deaths_thresh) %>% 
  inner_join(country_pops, by = c("country" = "country")) %>% 
  arrange(country, date) %>% 
  group_by(country) %>% 
  mutate(
    cum_deaths = cumsum(deaths),
    tenth_death_date = date[cum_deaths >= 10][[1]],
    days_since_tenth_death = as.integer(date - tenth_death_date),
    deaths_smoothed = smooth.spline(deaths)$y,
    deaths_per_million_smoothed = deaths_smoothed / population * 1e6,
    total_deaths_per_million = total_deaths / population * 1e6,
    deaths_per_million_smoothed_yesterday = 
      deaths_per_million_smoothed[
        days_since_tenth_death = which.max(days_since_tenth_death)
      ]
  ) %>% 
  ungroup() %>% 
  filter(total_deaths >= total_deaths_thresh, days_since_tenth_death >= 0) %>% 
  inner_join(countries_iso3c, by = c("country" = "country")) %>% 
  select(
    country, 
    iso3c,
    days_since_tenth_death, 
    deaths_per_million_smoothed,
    total_deaths_per_million,
    deaths_per_million_smoothed_yesterday
  ) %>% 
  arrange(total_deaths_per_million, country, days_since_tenth_death) %>% 
  write_csv(
    here::here(
      "content/post/data", 
      str_glue("world-data_snapshot-{lubridate::today()}.csv")
    )
  )
```

## A note on social distancing

Social distancing is mostly new (where it exists at all) and due to the long (approximately 2-week) latency period of the virus (_latency_ is roughly the period between a person encountering the virus and showing symptoms of infection), we probably won't see the benefit of social distancing in these statistics for at least another week. If by then there's still no improvement, that would be cause for huge concern. In Taiwan, for example, the government is using people's mobile phone location to ensure they stay at home. If you leave home without permission, the police come and find you within a half hour and make you return home. That is a much better lockdown than exists anywhere in the western world. I was in a crowded supermarket yesterday in Oakland, California. I'd be surprised if there wasn't a single transmission in there that day. The local lake is more crowded than ever with people who are desperate to get outside. They _try_ to keep their distance, but they're not as distant as they would be if they'd stayed at home. Are we doing _enough_? We'll have a better idea in a few weeks.


# World data

## All countries

I'm going to limit the data to countries that have reported at least `r total_deaths_thresh` deaths. First up, I'll just plot all of these countries. I'll give a table of country codes at the end. Note that the data is not cumulative: each data point is deaths per million on that day. The lines are colored by how bad the situation is in that country right now: how many deaths there were there yesterday.

```{r all-countries}
ggplot(
  data, 
  aes(
    x = days_since_tenth_death,
    y = deaths_per_million_smoothed,
    colour = deaths_per_million_smoothed_yesterday,
    group = iso3c
  )
) + 
  geom_line() + 
  geom_dl(aes(label = iso3c), 
          method = list("last.points", cex = 4/3)) +
  labs(x = "days since tenth death", y = "deaths per million",
       colour = "deaths\nper\nmillion\nyesterday") +
  scale_colour_gradient(low = "blue", high = "red") + 
  xlim(0, max(data$days_since_tenth_death) + 2) + 
  theme(text = element_text(size = 20))
```

```{r spain-italy}
spain_yesterday <- data %>% 
  filter(iso3c == "ESP") %>% 
  filter(days_since_tenth_death == max(days_since_tenth_death)) 
spain_days_after <- spain_yesterday$days_since_tenth_death
spain_yesterday_deaths_per_mil_smoothed <- 
  round(spain_yesterday$deaths_per_million_smoothed)
italy_that_day_deaths_per_mil_smoothed <- data %>% 
  filter(iso3c == "ITA", days_since_tenth_death == spain_days_after) %>% 
  pull(deaths_per_million_smoothed) %>% 
  round()
```

* We can see that **Spain** has (predictably) gotten worse than **Italy**. Italy has managed to contain enough to make their curve linear; Spain still looks to be in exponential growth and has surpassed Italy in deaths per million per day. `r spain_days_after` days after its tenth death, it's up to `r spain_yesterday_deaths_per_mil_smoothed` deaths per million that day, whereas Italy was on `r italy_that_day_deaths_per_mil_smoothed` deaths per million on its equivalent day. Linear growth is still catastrophic for Italy. Their deaths per day are huge and growing.
* **The Netherlands** and **Belgium** appear to be in serious danger of ending up worse than Italy.

```{r subset-1}
subset1_deaths_per_million_thresh <- 10
```

The other countries are a bit bunched, so next I'll limit the plot to countries with less than `r subset1_deaths_per_million_thresh` deaths per million yesterday.


## Countries with less than `r subset1_deaths_per_million_thresh` deaths per million yesterday

```{r lt5-deaths-per-mil}
ggplot(
  filter(
    data, 
    deaths_per_million_smoothed_yesterday < subset1_deaths_per_million_thresh
  ), 
  aes(
    x = days_since_tenth_death,
    y = deaths_per_million_smoothed,
    colour = deaths_per_million_smoothed_yesterday,
    group = iso3c
  )
) + 
  geom_line() + 
  geom_dl(aes(label = iso3c), 
          method = list("last.points", cex = 4/3)) +
  labs(x = "days since tenth death", y = "deaths per million",
       colour = "deaths\nper\nmillion\nyesterday") +
  scale_colour_gradient(low = "blue", high = "red") + 
  xlim(0, max(data$days_since_tenth_death) + 2) + 
  theme(text = element_text(size = 20))
```

* **Sweden** are fast going the way of the Netherlands. Both tried _herd immunity_ and it appears to be failing them. 
* **Iran** looked to be turning the corner and lowering their fatalities but now they've ticked back up again. [Note that Iran's data is some of the least trustworthy.]
* **Great Britain** is getting really bad right now. look how steep their curve is.
* **Switzerland** is between The Netherlands and France.

```{r subset-2}
subset2_deaths_per_million_thresh <- 2
```


## Countries with less than `r subset2_deaths_per_million_thresh` death per million yesterday

```{r lt1-death-per-mil}
ggplot(
  filter(
    data, 
    deaths_per_million_smoothed_yesterday < subset2_deaths_per_million_thresh
  ), 
  aes(
    x = days_since_tenth_death,
    y = deaths_per_million_smoothed,
    colour = deaths_per_million_smoothed_yesterday,
    group = iso3c
  )
) + 
  geom_line() + 
  geom_dl(aes(label = iso3c), 
          method = list("last.points", cex = 4/3)) +
  labs(x = "days since tenth death", y = "deaths per million",
       colour = "deaths\nper\nmillion\nyesterday") +
  scale_colour_gradient(low = "blue", high = "red") + 
  xlim(0, max(data$days_since_tenth_death) + 2) + 
  theme(text = element_text(size = 20))
```

* The **USA** curve looks ominously steep here. They have 3 main states (California, New York and Washington) driving most of their cases and deaths. See below for a breakdown of the US by states.
* **Germany**'s growth looks like the numbers that Iran were reporting a month ago.
* **China** is the only country which looks to have beaten their outbreak. They deserve enormous credit for their (post cover-up) response, and a lot can be learned from what they did. Of course, the number of cases there could rise again, but they know what to do if that happens. [China's data is somewhat untrustworthy though: one day this week they reported 0 new cases and I don't buy that.]
* **South Korea** has managed to keep its death numbers in a linear regime (growing at constant number of people dying every day) or perhaps slightly better. This is also a great achievement, given how nearly every other country is displaying exponential growth. Still, they need to improve further. More people died there yesterday than the day before; that needs to change.


# US data

I'm going to use the same limitations for the US state data: states with at least 100 deaths. For reference, I'm also going to include Spain and Italy.

```{r prep-US-data}
pacman::p_load(covid19us, tidycensus, openintro)
pop_thresh <- 7.5e6
state_pops <- get_estimates(geography = "state", product = "population") %>% 
  filter(variable == "POP", NAME != "Puerto Rico") %>% 
  transmute(state = state2abbr(NAME), population = value)
us_data <- get_states_daily() %>% 
  select(date, state, death) %>% 
  rename(deaths = death) %>% 
  mutate(deaths = replace_na(deaths, 0L)) %>% 
  inner_join(state_pops, by = c("state" = "state")) %>% 
  add_count(state, wt = deaths, name = "total_deaths") %>% 
  filter(total_deaths >= 10) %>% 
  arrange(state, date) %>% 
  group_by(state) %>% 
  mutate(
    cum_deaths = cumsum(deaths),
    tenth_death_date = date[cum_deaths >= 10][[1]],
    days_since_tenth_death = as.integer(date - tenth_death_date),
    deaths_smoothed = suppressMessages(
      smooth.spline(deaths, cv = TRUE)
    )$y,
    deaths_per_million_smoothed = deaths_smoothed / population * 1e6,
    total_deaths_per_million = total_deaths / population * 1e6,
    deaths_per_million_smoothed_yesterday = 
      deaths_per_million_smoothed[
        days_since_tenth_death = which.max(days_since_tenth_death)
      ]
  ) %>% 
  ungroup() %>% 
  filter(total_deaths >= total_deaths_thresh, days_since_tenth_death >= 0) %>% 
  select(
    state, 
    days_since_tenth_death, 
    deaths_per_million_smoothed,
    total_deaths_per_million,
    deaths_per_million_smoothed_yesterday,
    total_deaths
  ) %>% 
  arrange(total_deaths_per_million, state, days_since_tenth_death) %>% 
  write_csv(
    here::here(
      "content/post/data", 
      str_glue("us-data_snapshot-{lubridate::today()}.csv")
    )
  )
```

```{r us-plot}
us_plot_data <- bind_rows(
  us_data,
  data %>%
    select(-country) %>% 
    filter(iso3c %in% c("ESP", "ITA")) %>% 
    rename(state = iso3c)
)
ggplot(
  us_plot_data, 
  aes(
    x = days_since_tenth_death,
    y = deaths_per_million_smoothed,
    colour = deaths_per_million_smoothed_yesterday,
    group = state
  )
) + 
  geom_line() + 
  geom_dl(aes(label = state), 
          method = list("last.points", cex = 4/3)) +
  labs(x = "days since tenth death", y = "deaths per million",
       colour = "deaths\nper\nmillion\nyesterday") +
  scale_colour_gradient(low = "blue", high = "red") + 
  xlim(0, max(us_plot_data$days_since_tenth_death) + 2) + 
  theme(text = element_text(size = 20))
```

```{r us-state-specifics}
wa_days_since_tenth_death <- us_data %>% 
  filter(state == "WA") %>% 
  pull(days_since_tenth_death) %>% 
  max()
wa_current_deaths_per_million <- us_data %>% 
  filter(state == "WA", days_since_tenth_death == wa_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)
spain_wa_equivalent_deaths_per_million <- data %>% 
  filter(iso3c == "ESP", days_since_tenth_death == wa_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)

ny_days_since_tenth_death <- us_data %>% 
  filter(state == "NY") %>% 
  pull(days_since_tenth_death) %>% 
  max()
ny_current_deaths_per_million <- us_data %>% 
  filter(state == "NY", days_since_tenth_death == ny_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)
spain_ny_equivalent_deaths_per_million <- data %>% 
  filter(iso3c == "ESP", days_since_tenth_death == ny_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)

nj_days_since_tenth_death <- us_data %>% 
  filter(state == "NJ") %>% 
  pull(days_since_tenth_death) %>% 
  max()
nj_current_deaths_per_million <- us_data %>% 
  filter(state == "NJ", days_since_tenth_death == nj_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)
spain_nj_equivalent_deaths_per_million <- data %>% 
  filter(iso3c == "ESP", days_since_tenth_death == nj_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)

ca_days_since_tenth_death <- us_data %>% 
  filter(state == "CA") %>% 
  pull(days_since_tenth_death) %>% 
  max()
ca_current_deaths_per_million <- us_data %>% 
  filter(state == "CA", days_since_tenth_death == ca_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)

la_days_since_tenth_death <- us_data %>% 
  filter(state == "LA") %>% 
  pull(days_since_tenth_death) %>% 
  max()
la_current_deaths_per_million <- us_data %>% 
  filter(state == "LA", days_since_tenth_death == la_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)
ny_la_equivalent_deaths_per_million <- us_data %>% 
  filter(state == "NY", days_since_tenth_death == la_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)

ga_days_since_tenth_death <- us_data %>% 
  filter(state == "GA") %>% 
  pull(days_since_tenth_death) %>% 
  max()
ga_current_deaths_per_million <- us_data %>% 
  filter(state == "GA", days_since_tenth_death == ga_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)
spain_ga_equivalent_deaths_per_million <- data %>% 
  filter(iso3c == "ESP", days_since_tenth_death == ga_days_since_tenth_death) %>% 
  pull(deaths_per_million_smoothed)
```


* **Washington** state is at `r round(wa_current_deaths_per_million)` deaths per million `r wa_days_since_tenth_death` days after its tenth death. At this point, Spain was at `r round(spain_wa_equivalent_deaths_per_million)` deaths per million. This is absolutely dire. One bright light for Washington is that they have avoided exponential growth in the death rate, but the linear growth they have is still a massive problem.
* **New York** is at `r round(ny_current_deaths_per_million)` deaths per million `r ny_days_since_tenth_death` days after its tenth death. At this point, Spain was at `r round(spain_ny_equivalent_deaths_per_million)` deaths per million. 
* **Louisiana** is looking worse than New York. It's at `r round(la_current_deaths_per_million)` deaths per million `r la_days_since_tenth_death` days after its tenth death. At this point, New York was at `r round(ny_la_equivalent_deaths_per_million)` deaths per million.
* **Michigan** is somewhere between New York and Louisiana.
* **New Jersey** looks certain to be worse than Washington. It's at `r round(nj_current_deaths_per_million)` deaths per million `r nj_days_since_tenth_death` days after its tenth death; better than New York but not good at all. At this point, Spain was at `r round(spain_nj_equivalent_deaths_per_million)` deaths per million.
* **Georgia** s at `r round(nj_current_deaths_per_million)` deaths per million `r nj_days_since_tenth_death` days after its tenth death; better than New York but not good at all. At this point, Spain was at `r round(spain_nj_equivalent_deaths_per_million)` deaths per million.
* **Illinois** looks to be somewhere between Georgia and Spain.
* `r round(ca_days_since_tenth_death)` days after its tenth death, **California** is at approximately `r round(ca_current_deaths_per_million)` `r if_else(round(ca_current_deaths_per_million) == 1, "death", "deaths")` per million. This is similar to where Italy was at this stage. California and Italy have interesting parallels. They have similar situations and they have single main epicenters of their outbreaks (Los Angeles and Lombardy).
* **Florida** looks very like California with a few days' lag. Florida could get very bad with the density of old people there.
* For **Connecticut** and **Massachusetts** it's too early to say, but they look to be going the way of Michigan.

# Appendix

```{r country-codes}
data %>% 
  distinct(iso3c, country) %>%
  filter(!str_starts(country, coll("US"))) %>% 
  arrange(iso3c) %>% {
    if (FSA::is.odd(nrow(.))) {
      . <- bind_rows(
        ., 
        tibble(iso3c = "", country = "")
      )
    }
    first_half <- seq_len(nrow(.) / 2)
    last_half <- setdiff(seq_len(nrow(.)), first_half)
    bind_cols(.[first_half, ], .[last_half, ])
  } %>% 
  set_names(names(.)[c(1, 2, 1, 2)]) %>% 
  knitr::kable()
```